#! /bin/bash

# Expected context:  running inside Docker

# Primary command script passed into Batch container runs

# caldp-process  dataset  <input_path>  <output_path>  <caldp_config>

dataset=$1
input_path=${2:-"file:."}
output_path=${3:-"file:."}
caldp_config=${4:-"caldp-config-onsite"}

# Configure TIME to point to Gnu's time program which can collect process metrics.
if [ `uname` = "Darwin" -a -f /usr/local/bin/gtime ]; then  # brew install gnu-time
    TIME=/usr/local/bin/gtime
elif [ `uname` = "Linux" ]; then
    TIME=/usr/bin/time
else
    TIME=eval
fi

echo "Starting caldp-process at (input) ${input_path} (output) ${output_path} for ${dataset} using config ${caldp_config}"

source ${caldp_config}

# When running inside Docker, the CRDS cache is *always* at $HOME/crds_cache,
# but may or may not be writeable, and may or may not be dynamic.
if [[ ${CALDP_DOCKER} != "" ]]; then
    export CRDS_PATH=/grp/crds/cache
fi

# This may not work for all CRDS caches unless they are re-organized using the CRDS
# sync tool to be "flat" as well as readonly.  Most existing HST readonly pipeline caches
# should already be flat.  Newly created caches are automatically "instrument" unless
#  reorganized...  which is the offsite / read-write case.
if  [[ ${CRDS_READONLY_CACHE} == "1" ]]; then
    export iref=${CRDS_PATH}/references/hst/
    export jref=${CRDS_PATH}/references/hst/
    export oref=${CRDS_PATH}/references/hst/
    export lref=${CRDS_PATH}/references/hst/
    export nref=${CRDS_PATH}/references/hst/
    export uref=${CRDS_PATH}/references/hst/
    export uref_linux=$uref
else
    export iref=${CRDS_PATH}/references/hst/wfc3/
    export jref=${CRDS_PATH}/references/hst/acs/
    export oref=${CRDS_PATH}/references/hst/stis/
    export lref=${CRDS_PATH}/references/hst/cos/
    export nref=${CRDS_PATH}/references/hst/nicmos/
    export uref=${CRDS_PATH}/references/hst/wfcpc2/
    export uref_linux=$uref
fi

echo ........................................ Environment ..............................................
echo "User is" `whoami`
echo "Current dir is" `pwd`
printenv | sort

echo ........................................ Directory Perms  ..............................................
ls -ld .

echo ........................................ Ulimits ..............................................
ulimit -a

output_location=`echo $output_path | cut -d':' -f1`

if [ $output_path != "none" -a $output_location == 's3' ]; then
    echo ........................................ S3 read check  ..............................................
    bucket=`echo $output_path | cut -d'/' -f3`
    aws s3 ls $bucket
    if [[ $? -ne  0 ]]; then
        echo "XXXXXX  S3 read check failed at ${output_path}."
        exit 1
    fi
    # get crds context from S3
    echo ........................................ OPERATOR CONTROLLED CRDS  ...................................
    flist=$(aws s3 ls $bucket/crds_env_vars/ | grep ".pmap")
    export CRDS_CONTEXT=`echo $flist | awk '{print $4}'`
    echo "CRDS_CONTEXT is set to ${CRDS_CONTEXT} from ${bucket}/crds_env_vars/"
fi

echo ........................................ processing log ..............................................
pwd
set -o pipefail && $TIME --verbose -o process_metrics.txt \
    python -m caldp.process $input_path $output_path $dataset

process_exit_status=$?
echo "Processing exit status ${process_exit_status}"

processing_output_dir=`caldp-get-output-path  $output_path $dataset`
echo "Processing output_dir is" $processing_output_dir

previews_output_dir="${processing_output_dir}/previews"
echo "Previews output_dir is" $previews_output_dir

echo ........................................ previews log ................................................


set -o pipefail && $TIME --verbose -o preview_metrics.txt \
    python -m caldp.create_previews $input_path $output_path $dataset

preview_exit_status=$?
echo "Preview exit status ${preview_exit_status}"


echo ........................................ process metrics .............................................
cat process_metrics.txt

echo ........................................ preview metrics .............................................
cat preview_metrics.txt

echo ........................... handling outputs for ${output_location} ..................................

# Note: this action is not logged since log files are being transferred.
python -m caldp.messages $input_path $output_path $dataset
messages_exit_status=$?
echo "messages exit status = ${messages_exit_status}"

# This is iffy:  only report MemoryError if the program returns non-zero status.  Otherwise assume it dealt with it.
if [[ $process_exit_status -ne 0 ]]; then
    grep MemoryError process.txt
    if [[ $? -eq 0 ]]; then
        echo "MemoryError found in process.txt;  exiting with status 31,  SUBPROCESS_MEMORY_ERROR"
        exit 31
    else
        echo "Exiting with processing status ${process_exit_status}"
        exit $process_exit_status
    fi
fi

if [[ $preview_exit_status -ne 0 ]]; then
    echo "Exiting with preview status ${preview_exit_status}"
    exit $preview_exit_status
fi

if [[ $messages_exit_status -ne 0 ]]; then
    echo "Exiting with message status ${messages_exit_status}"
    exit $preview_exit_status
fi

echo "Exiting normally, status 0"
exit 0
